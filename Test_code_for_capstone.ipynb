{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1nxYXbsR1tXcMhMvOUW_dMGynpQFzxNKD",
      "authorship_tag": "ABX9TyPWtEaw47Xkvnti0FuSEhB8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mra49/Capstone/blob/main/Test_code_for_capstone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Bitsy EDA's"
      ],
      "metadata": {
        "id": "XpPYeUHYRnT9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGP8biQFFw0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c677a66-c892-4f3f-f47c-359e76b02423"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   Item Description  Total Extended Price\n",
            "72            foamy dishwash 6000ml          2.172554e+06\n",
            "102      foamy laundry power gel 5l          2.154178e+06\n",
            "181  style apple blossom sh. 4000ml          1.300975e+06\n",
            "226  style shampoo cool ocean 4000m          1.218185e+06\n",
            "91     foamy general cleaner 6000ml          1.196581e+06\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Group by 'Item Description' and sum the 'Extended Price'\n",
        "grouped_data = df_rfm.groupby('Item Description')['Extended Price'].sum().reset_index()\n",
        "\n",
        "# Rename the columns for clarity\n",
        "grouped_data.columns = ['Item Description', 'Total Extended Price']\n",
        "\n",
        "#sort data\n",
        "sorted_data = grouped_data.sort_values(by='Total Extended Price', ascending=False)\n",
        "\n",
        "# Output the result\n",
        "print(sorted_data.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Group by 'Item Number' and filter out those that appear less than 10 times, then overwrite df\n",
        "df = df.groupby('Item Number').filter(lambda x: len(x) >= 10)"
      ],
      "metadata": {
        "id": "lo_59SB1kY6c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#not eda's"
      ],
      "metadata": {
        "id": "wvD9DMwekUv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##############  Test sample for prev checkPoint: DF_FAULT CONTAINS TWO COLUMNS THE UNIQUE IDS AND THEIR DESCRIPTION BUT ONLY IN'S THAT SHARE THE DESC ##############################\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df_copy is your DataFrame and it's already loaded\n",
        "\n",
        "# Group by 'Item Description' and count the unique 'Item Numbers' for each description\n",
        "description_counts = df_copy.groupby('Item Description')['Item Number'].nunique()\n",
        "\n",
        "# Filter to get descriptions that are associated with more than one 'Item Number'\n",
        "duplicate_descriptions = description_counts[description_counts > 1].index.tolist()\n",
        "\n",
        "# Create a DataFrame with 'Item Number' and 'Item Description' where the descriptions are duplicated\n",
        "df_fault = df_copy[df_copy['Item Description'].isin(duplicate_descriptions)][['Item Number', 'Item Description']]\n",
        "\n",
        "# Drop duplicates to avoid repeating the same 'Item Number' with the same 'Item Description'\n",
        "df_fault = df_fault.drop_duplicates()\n",
        "df_fault.to_csv(\"df_fault.csv\", index = False)\n",
        "print(df_fault)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwrPo-6PnYIg",
        "outputId": "3c22f36b-947e-42c1-a153-181cf8ceb38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Item Number                Item Description\n",
            "1            56240            style mask kiwi 500g\n",
            "36           52439  reflet argent gris nacre shamp\n",
            "43           56592  style bone marrow conditioning\n",
            "58           56979  style bone marrow conditioning\n",
            "63           55562  style shampoo apple blossom 22\n",
            "...            ...                             ...\n",
            "86462        76654  foamy dishwashing liquid lemon\n",
            "91701        76656  foamy laundry power gel 3100ml\n",
            "102626       76666  foamy floor cleaner 5.1l + foa\n",
            "102640       76665  foamy laundry 5.1l + foamy fab\n",
            "102641       76667  foamy floor cleaner 5.1l + foa\n",
            "\n",
            "[74 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "############   Testing the Unifying Item Numbers Method applied on df_copy   ############\n",
        "import pandas as pd\n",
        "\n",
        "# Assuming df_fault is your DataFrame and it's already loaded\n",
        "\n",
        "# Sort df_fault by 'Item Description' and 'Item Number'\n",
        "df_fault_sorted = df_fault.sort_values(by=['Item Description', 'Item Number'])\n",
        "\n",
        "# Group by 'Item Description' and select the first 'Item Number' as the representative\n",
        "# Add a zero at the beginning of each representative 'Item Number'\n",
        "rep_item_numbers = df_fault_sorted.groupby('Item Description')['Item Number'].first().apply(lambda x: '0' + str(x))\n",
        "\n",
        "# Create a mapping from 'Item Description' to the modified representative 'Item Number'\n",
        "description_to_rep_item_number = rep_item_numbers.to_dict()\n",
        "\n",
        "# Map the representative 'Item Number' back to the df_fault DataFrame in a new column 'Unified Description'\n",
        "df_fault['Unified Description'] = df_fault['Item Description'].map(description_to_rep_item_number)\n",
        "\n",
        "# df_fault now has an additional column 'Unified Description'\n"
      ],
      "metadata": {
        "id": "D7LOUITn0Dp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming df_fault is your DataFrame and it's already loaded\n",
        "\n",
        "# Count the number of unique item numbers in the 'Item Number' column\n",
        "unique_item_numbers_count = df_fault['Item Number'].nunique()\n",
        "print(f\"Number of unique Item Numbers: {unique_item_numbers_count}\")\n",
        "\n",
        "# Count the number of unique item numbers in the 'Unified Description' column\n",
        "unique_unified_numbers_count = df_fault['Unified Description'].nunique()\n",
        "print(f\"Number of unique Unified Descriptions: {unique_unified_numbers_count}\")\n",
        "print(df_fault.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M1oX7zwfbiz",
        "outputId": "86735ca4-0f31-4bd2-a90f-5a4595644084"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of unique Item Numbers: 74\n",
            "Number of unique Unified Descriptions: 31\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 74 entries, 1 to 102641\n",
            "Data columns (total 3 columns):\n",
            " #   Column               Non-Null Count  Dtype \n",
            "---  ------               --------------  ----- \n",
            " 0   Item Number          74 non-null     object\n",
            " 1   Item Description     74 non-null     object\n",
            " 2   Unified Description  74 non-null     object\n",
            "dtypes: object(3)\n",
            "memory usage: 2.3+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_fault.to_csv(\"df_fault.csv\", index = False)"
      ],
      "metadata": {
        "id": "KVZ47YxZpGJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Count how many 'No' values are in the 'Unique Description' column\n",
        "non_unique_count = (df_copy['Unique Description'] == 'No').sum()\n",
        "print(f\"Number of item numbers with non-unique descriptions: {non_unique_count}\")\n",
        "\n",
        "#here there's a flow, while the yes and no column is important, it's hindering or making the process of calculating how many missings more comlicated\n",
        "\n",
        "# Count the number of unique item descriptions in the 'Item Description' column\n",
        "unique_descriptions_count = df_copy['Item Description'].nunique()\n",
        "print(f\"There are {unique_descriptions_count} unique item descriptions.\")\n",
        "\n",
        "unique_descriptions_count = df_copy['Item Number'].nunique()\n",
        "print(f\"There are {unique_descriptions_count} unique item numbers.\")\n",
        "print(\"This means that there are Item Numbers with the same Item Description\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvwrBG8J6e71",
        "outputId": "8dff2ef0-b248-47af-9780-69fe2f0206f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of item numbers with non-unique descriptions: 0\n",
            "There are 879 unique item descriptions.\n",
            "There are 922 unique item numbers.\n",
            "This means that there are Item Numbers with the same Item Description\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uboFQb1r6TFA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Price Cleaning"
      ],
      "metadata": {
        "id": "o8lLInHmlAUv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Capstone/df_latest.csv\")"
      ],
      "metadata": {
        "id": "EQwePQQd6Tkd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVqPuQyqxYDB",
        "outputId": "28613de2-7f80-48e9-a05a-fb0a4f44b1c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Location', 'Brand', 'SubBrand', 'Category', 'SOP Number',\n",
              "       'Item Number', 'Item Description', 'QTY', 'Unit Price',\n",
              "       'Extended Price', 'Customer Number', 'Document Date', 'Item Short Name',\n",
              "       'Customer Name', 'Location ID', 'Offer Status', 'product_type',\n",
              "       'product_scent', 'product_size', 'Description Length', 'Subcategory',\n",
              "       'With Offer', 'Day', 'Month', 'Year'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rate_df = pd.read_csv(\"/content/drive/MyDrive/Capstone/usd-lbp.csv\")"
      ],
      "metadata": {
        "id": "WAbY-BIb7MPW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the date-time column in rate_df to datetime and extract the date part\n",
        "rate_df['Date'] = pd.to_datetime(rate_df['DateTime']).dt.date\n",
        "\n",
        "# Aggregate rate_df to have only one rate per date if there are multiple entries per date\n",
        "# Here, we are taking the mean of the rates for each date\n",
        "daily_rates = rate_df.groupby('Date')['USD to LBP'].mean().reset_index()\n",
        "\n",
        "# Convert the date column in df to datetime (if it's not already)\n",
        "df['Document Date'] = pd.to_datetime(df['Document Date']).dt.date\n",
        "\n",
        "# Merge the DataFrames on the date column\n",
        "# This will add the mean daily rate to your main df\n",
        "df_merged = pd.merge(df, daily_rates, left_on='Document Date', right_on='Date', how='left')\n",
        "\n",
        "# Drop the extra 'Date' column from the merge if you wish\n",
        "df_merged.drop('Date', axis=1, inplace=True)\n"
      ],
      "metadata": {
        "id": "3HmP_GV38mX1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_merged.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2lqb8OH9FAo",
        "outputId": "4e5b152b-3756-46a9-983b-33848e4ada55"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Location', 'Brand', 'SubBrand', 'Category', 'SOP Number',\n",
              "       'Item Number', 'Item Description', 'QTY', 'Unit Price',\n",
              "       'Extended Price', 'Customer Number', 'Document Date', 'Item Short Name',\n",
              "       'Customer Name', 'Location ID', 'Offer Status', 'product_type',\n",
              "       'product_scent', 'product_size', 'Description Length', 'Subcategory',\n",
              "       'With Offer', 'Day', 'Month', 'Year', 'USD to LBP'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = df_merged"
      ],
      "metadata": {
        "id": "zx_nf-p29ZXt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "\n",
        "# # Ensure the DataFrame is sorted by date\n",
        "# df.sort_values(by='Document Date', inplace=True)\n",
        "\n",
        "# # Identify the top 10 selling product types\n",
        "# top_product_types = df.groupby('product_type')['QTY'].sum().nlargest(10).index\n",
        "\n",
        "\n",
        "# # Function to adjust price\n",
        "# def adjust_price(row):\n",
        "#     if row['product_type'] in top_product_types and row['Unit Price'] > 16:\n",
        "#         # Filter to find prices for the same item on earlier dates, less than $25 but more than $2.5\n",
        "#         previous_prices = df[(df['Document Date'] < row['Document Date']) &\n",
        "#                              (df['Item Number'] == row['Item Number']) &\n",
        "#                              (df['Unit Price'] < 16) &\n",
        "#                              (df['Unit Price'] > 2.5)]\n",
        "\n",
        "#         # Sort by date to get the closest previous price\n",
        "#         previous_prices = previous_prices.sort_values(by='Document Date', ascending=False)\n",
        "\n",
        "#         # Check if there are any such prices and return the closest one, else return the current price\n",
        "#         if not previous_prices.empty:\n",
        "#             return previous_prices.iloc[0]['Unit Price']\n",
        "#         else:\n",
        "#             return row['Unit Price']\n",
        "#     else:\n",
        "#         return row['Unit Price']\n",
        "\n",
        "# # Apply the function to create the 'calculated price' column\n",
        "# df['calculated price'] = df.apply(adjust_price, axis=1)"
      ],
      "metadata": {
        "id": "wn6ICF9ak_3G"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Capstone')"
      ],
      "metadata": {
        "id": "5fGAG-Ou-Ddq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['USD to LBP'].head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugaKKgR5plSa",
        "outputId": "b52d817f-32e1-463c-f6b9-7c04c8f16ad8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2118.333333\n",
              "1    2118.333333\n",
              "2    2118.333333\n",
              "3    2118.333333\n",
              "4    2118.333333\n",
              "Name: USD to LBP, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dotg87JfsKxz",
        "outputId": "ff143d68-e9d6-4084-889c-cadcf40de663"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101542, 25)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the top 10 selling product types\n",
        "top_product_types = df.groupby('product_type')['QTY'].sum().nlargest(10).index\n",
        "\n",
        "# Ensure that 'Unit Price' and 'USD to LBP' are numeric\n",
        "df['Unit Price'] = pd.to_numeric(df['Unit Price'], errors='coerce')\n",
        "df['USD to LBP'] = pd.to_numeric(df['USD to LBP'], errors='coerce')\n",
        "\n",
        "# Replace 0 with 1 in 'USD to LBP' to avoid division by zero\n",
        "df['USD to LBP'].replace(0, 1, inplace=True)\n",
        "df['USD to LBP'].fillna(1, inplace=True) # Replace NaN with 1\n",
        "\n",
        "# Function to calculate the adjusted rate\n",
        "def calculate_rate(row):\n",
        "    if row['product_type'] in top_product_types and row['Unit Price'] > 17 and row['USD to LBP'] != 1:\n",
        "        return (row['Unit Price'] * 1500) / row['USD to LBP']\n",
        "    else:\n",
        "        return row['Unit Price']\n",
        "\n",
        "# Apply the function to create the 'rate_calculated' column\n",
        "df['rate_calculated'] = df.apply(calculate_rate, axis=1)\n"
      ],
      "metadata": {
        "id": "pRs7ms5pPJTn"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m-AZfmK-dsCk",
        "outputId": "e005e145-b225-49d3-fcd1-af26d20a8299"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(101542, 27)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['rate_calculated'].head(35)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7iIeLW6BN_w",
        "outputId": "e7574366-a1a4-40bb-a07c-8509d714c142"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      8.670000\n",
              "1      0.000000\n",
              "2     11.020000\n",
              "3      2.098000\n",
              "4      6.904000\n",
              "5      0.788000\n",
              "6      0.899000\n",
              "7      0.400000\n",
              "8      1.585000\n",
              "9      8.670000\n",
              "10     8.670000\n",
              "11     8.670000\n",
              "12    14.700000\n",
              "13     0.000000\n",
              "14     0.000000\n",
              "15     0.000000\n",
              "16     0.000000\n",
              "17     0.000000\n",
              "18    12.214792\n",
              "19    12.214792\n",
              "20    97.680000\n",
              "21     1.498000\n",
              "22     0.000000\n",
              "23     0.000000\n",
              "24     0.000000\n",
              "25    14.700000\n",
              "26    14.700000\n",
              "27    14.700000\n",
              "28    14.700000\n",
              "29     3.297000\n",
              "30    12.214792\n",
              "31     0.000000\n",
              "32     3.331000\n",
              "33     0.000000\n",
              "34     3.331000\n",
              "Name: rate_calculated, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming 'df' is your DataFrame and it has columns 'product_type' and 'QTY'\n",
        "\n",
        "# Calculate the total sales for each product type\n",
        "total_sales_by_type = df.groupby('product_type')['QTY'].sum()\n",
        "\n",
        "# Identify the top 10 selling product types\n",
        "top_product_types = total_sales_by_type.nlargest(10)\n",
        "\n",
        "# Calculate the total sales of the top 10 selling product types\n",
        "total_sales_top_10 = top_product_types.sum()\n",
        "\n",
        "# Calculate the total sales in the entire DataFrame\n",
        "total_sales_overall = total_sales_by_type.sum()\n",
        "\n",
        "# Calculate the proportion\n",
        "proportion_top_10 = total_sales_top_10 / total_sales_overall\n",
        "\n",
        "# Print the proportion\n",
        "print(f\"The top 10 selling product types represent {proportion_top_10:.2%} of the total amount sold.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6eO2HrfKIuN",
        "outputId": "bf1f31f9-119d-4720-b890-15e5a08d8461"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The top 10 selling product types represent 93.70% of the total amount sold.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_product_types"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHJD9bPCKWzr",
        "outputId": "b71425ff-dc33-496e-d05e-4dcdd5e58bd3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "product_type\n",
              "shampoo              643253\n",
              "dishwashing          334949\n",
              "laundry gel          110772\n",
              "general cleaner       81862\n",
              "hand soap             63985\n",
              "disinfectant          59659\n",
              "multi-use shampoo     49957\n",
              "fabric softner        33992\n",
              "floor cleaner         22988\n",
              "shower gel            16784\n",
              "Name: QTY, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"df_prices_adjusted.csv\", index = False)"
      ],
      "metadata": {
        "id": "jhvVCHfh_vdA"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming your DataFrame is named df and it's already loaded\n",
        "\n",
        "# Convert 'Document Date' to datetime if it's not already\n",
        "df['Document Date'] = pd.to_datetime(df['Document Date'])\n",
        "\n",
        "# Extract day, month, and year\n",
        "df['Day'] = df['Document Date'].dt.day\n",
        "df['Month'] = df['Document Date'].dt.month\n",
        "df['Year'] = df['Document Date'].dt.year"
      ],
      "metadata": {
        "id": "vkhQUS6MpQ2t"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your original DataFrame\n",
        "df_invoice = df\n",
        "\n",
        "# Group by 'SOP Number' and aggregate\n",
        "invoice_df = df_invoice.groupby('SOP Number').agg({\n",
        "    'Item Number': pd.Series.nunique,\n",
        "    'Category': pd.Series.nunique,\n",
        "    'Subcategory': pd.Series.nunique,  # Assuming 'SubCategory' exists in df_rfm\n",
        "    'Extended Price': 'sum',\n",
        "    'QTY': 'sum',\n",
        "    'Customer Number': 'first',  # Assuming each invoice has exactly one customer\n",
        "    'Document Date': 'first',  # Date of the invoice\n",
        "    'Location ID': 'first',  # Location of the invoice\n",
        "    'SOP Number' : 'first'\n",
        "}).rename(columns={\n",
        "    'Item Number': 'Product Variety',\n",
        "    'Category': 'Category Variety',\n",
        "    'Subcategory': 'SubCategory Variety',\n",
        "    'Extended Price': 'Total Extended Price',\n",
        "    'QTY': 'Total QTY'\n",
        "})\n",
        "\n",
        "# Calculate Percentage Offered and Count of Distinct Offered Items\n",
        "offered_data = df_invoice[df_invoice['Offer Status'] == 'Offer'].groupby('SOP Number').agg({\n",
        "    'QTY': 'sum',\n",
        "    'Item Number': pd.Series.nunique\n",
        "}).rename(columns={\n",
        "    'Item Number': 'Distinct Offered Items'\n",
        "})\n",
        "\n",
        "invoice_df = invoice_df.merge(offered_data, how='left', left_index=True, right_index=True)\n",
        "invoice_df['Percentage Offered'] = invoice_df['QTY'] / invoice_df['Total QTY']\n",
        "invoice_df.drop(columns='QTY', inplace=True)  # Remove the extra 'QTY' column\n",
        "\n",
        "# Fill NaN values with appropriate defaults\n",
        "invoice_df['Percentage Offered'].fillna(0, inplace=True)\n",
        "invoice_df['Distinct Offered Items'].fillna(0, inplace=True)\n",
        "\n",
        "# Save the aggregated data to a CSV\n",
        "invoice_df.to_csv('invoice.csv', index=False)\n",
        "\n",
        "print(\"Aggregated invoice data saved to 'invoice.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4x4JFq8dm3-h",
        "outputId": "69302635-57f7-4805-c213-781b2bcdfebb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated invoice data saved to 'invoice.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to calculate RFM values\n",
        "# def calculate_rfm_up_to_date(customer_number, invoice_date, df):\n",
        "#     # Ensure invoice_date is a pandas Timestamp object\n",
        "#     invoice_date = pd.to_datetime(invoice_date)\n",
        "\n",
        "#     # Filter records for the customer up to the invoice date\n",
        "#     customer_data = df[(df['Customer Number'] == customer_number) &\n",
        "#                        (df['Document Date'] < invoice_date)]\n",
        "\n",
        "#     # Calculate Recency, Frequency, and Monetary\n",
        "#     last_purchase = customer_data['Document Date'].max()\n",
        "#     recency = (invoice_date - last_purchase).days if last_purchase else None\n",
        "#     frequency = customer_data['SOP Number'].nunique()\n",
        "#     monetary = customer_data['Extended Price'].sum()\n",
        "\n",
        "#     return recency, frequency, monetary\n",
        "    ##############################"
      ],
      "metadata": {
        "id": "DkeFUY5q96VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert 'Document Date' to datetime in the original DataFrame if it's not already\n",
        "df_invoice['Document Date'] = pd.to_datetime(df_invoice['Document Date'])\n",
        "\n",
        "# Ensure the DataFrame is sorted by 'Document Date'\n",
        "df_invoice.sort_values(by='Document Date', inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "def calculate_rfm_up_to_date(customer_number, invoice_date, df):\n",
        "    # Filter records for the customer up to the invoice date\n",
        "    invoice_date = pd.to_datetime(invoice_date)\n",
        "    customer_data = df[(df['Customer Number'] == customer_number) &\n",
        "                       (df['Document Date'] < invoice_date)]\n",
        "\n",
        "    # Calculate Recency\n",
        "    last_purchase = customer_data['Document Date'].max()\n",
        "    if pd.notnull(last_purchase):\n",
        "        recency = (invoice_date - last_purchase).days\n",
        "    else:\n",
        "        # For new customers, use a large number to indicate no previous purchase\n",
        "        recency = df['Document Date'].max() - df['Document Date'].min()\n",
        "        recency = (recency.days if pd.notnull(recency) else 0) + 1\n",
        "\n",
        "    # Calculate Frequency and Monetary\n",
        "    frequency = customer_data['SOP Number'].nunique()\n",
        "    monetary = customer_data['Extended Price'].sum()\n",
        "\n",
        "    return recency, frequency, monetary\n",
        "    ##############################\n",
        "\n",
        "# Create the RFM columns in invoice_df\n",
        "invoice_df['Invoice_R'] = None\n",
        "invoice_df['Invoice_F'] = None\n",
        "invoice_df['Invoice_M'] = None\n",
        "\n",
        "# Calculate RFM values for each row in invoice_df\n",
        "for index, row in invoice_df.iterrows():\n",
        "    r, f, m = calculate_rfm_up_to_date(row['Customer Number'], row['Document Date'], df_invoice)\n",
        "    invoice_df.at[index, 'Invoice_R'] = r\n",
        "    invoice_df.at[index, 'Invoice_F'] = f\n",
        "    invoice_df.at[index, 'Invoice_M'] = m\n",
        "\n",
        "# Save the results\n",
        "invoice_df.to_csv(\"invoice.csv\", index=False)\n",
        "print(\"RFM calculations are complete and saved to invoice.csv.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajEoKrAJmn5s",
        "outputId": "ac1a32c0-198b-4207-807d-bba8cb739713"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RFM calculations are complete and saved to invoice.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the results\n",
        "invoice_df.to_csv(\"invoice.csv\", index=False)\n",
        "print(\"RFM calculations are complete and saved to invoice.csv.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMF8pCA3vZ0e",
        "outputId": "2ba9017a-7df4-4ff8-c89b-c533fea442e5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RFM calculations are complete and saved to invoice.csv.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Assuming df is your DataFrame and it has the columns 'Customer Number', 'SOP Number', 'Item Number', 'Extended Price', 'Offer Status', and 'Location ID'\n",
        "\n",
        "# # Convert 'Document Date' to datetime if it's not already\n",
        "# df['Document Date'] = pd.to_datetime(df['Document Date'])\n",
        "\n",
        "# # Sort by 'Document Date' to ensure we're getting the first purchase when we group\n",
        "# df.sort_values(by='Document Date', inplace=True)\n",
        "\n",
        "# # Group by 'Customer Number' and get the first purchase\n",
        "# first_purchase_df = df.groupby('Customer Number').first().reset_index()\n",
        "\n",
        "# # For the \"buys again\" column, we need to see if there are more purchases beyond the first\n",
        "# # We can do this by checking if there's more than one unique 'SOP Number' per customer\n",
        "# buys_again = df.groupby('Customer Number')['SOP Number'].nunique() > 1\n",
        "\n",
        "# # Now we'll create a DataFrame from this series and reset the index so it can be merged\n",
        "# buys_again_df = buys_again.to_frame('Buys Again').reset_index()\n",
        "\n",
        "# # Replace True/False with 1/0\n",
        "# buys_again_df['Buys Again'] = buys_again_df['Buys Again'].astype(int)\n",
        "\n",
        "# # Merge this information back into the first_purchase_df\n",
        "# first_purchase_df = first_purchase_df.merge(buys_again_df, on='Customer Number', how='left')\n",
        "\n",
        "# # To calculate the percentage offered, we need to know the total quantity and offered quantity per SOP Number\n",
        "# total_qty_per_invoice = df.groupby('SOP Number')['QTY'].sum()\n",
        "# offered_qty_per_invoice = df[df['Offer Status'] == 'Offer'].groupby('SOP Number')['QTY'].sum()\n",
        "\n",
        "# # Calculate percentage offered and merge it back into first_purchase_df\n",
        "# percentage_offered_df = (offered_qty_per_invoice / total_qty_per_invoice).to_frame('Percentage Offered').reset_index()\n",
        "# first_purchase_df = first_purchase_df.merge(percentage_offered_df, on='SOP Number', how='left')\n",
        "\n",
        "# # Fill NaN values in 'Percentage Offered' with 0 (assuming NaN means no offer was made)\n",
        "# first_purchase_df['Percentage Offered'].fillna(0, inplace=True)\n",
        "\n",
        "# # Select only the columns we want to keep\n",
        "# first_purchase_df = first_purchase_df[['Customer Number', 'Document Date', 'Extended Price', 'Item Number', 'Percentage Offered', 'Location ID', 'Buys Again']]\n",
        "\n",
        "# # Rename columns for clarity\n",
        "# first_purchase_df.rename(columns={\n",
        "#     'Document Date': 'First Purchase Date',\n",
        "#     'Extended Price': 'First Invoice Value',\n",
        "#     'Item Number': 'Distinct Products',\n",
        "#     'Location ID': 'Purchase Location'\n",
        "# }, inplace=True)\n",
        "\n",
        "# # Now first_purchase_df is ready and contains all the information you wanted\n",
        "# first_purchase_df.to_csv('first_purchase_data.csv', index=False)\n",
        "# print(\"Aggregated first purchase data saved to 'first_purchase_data.csv'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-sIrsGiNnhl",
        "outputId": "cc68d1ab-f362-48b1-dac2-3c7a9cb49cc8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated first purchase data saved to 'first_purchase_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # First, group by 'Customer Number' and identify the first SOP Number (Invoice) for each customer\n",
        "# first_invoice_per_customer = df.groupby('Customer Number')['SOP Number'].first().reset_index()\n",
        "\n",
        "# # Merge this information with the original df to filter out only the first purchases\n",
        "# first_purchases = pd.merge(first_invoice_per_customer, df, on=['Customer Number', 'SOP Number'], how='left')\n",
        "\n",
        "# # Now group by 'Customer Number' and count the distinct 'Item Number' for the first purchase\n",
        "# distinct_products_first_purchase = first_purchases.groupby('Customer Number')['Item Number'].nunique().reset_index()\n",
        "\n",
        "# # Merge this count back into first_purchase_df\n",
        "# first_purchase_df = pd.merge(first_purchase_df, distinct_products_first_purchase, on='Customer Number', how='left')\n",
        "\n",
        "# # Rename the columns for clarity\n",
        "# first_purchase_df.rename(columns={\n",
        "#     'Item Number': 'Distinct Products in First Invoice'\n",
        "# }, inplace=True)\n",
        "\n",
        "# # Continue with the rest of your processing...\n"
      ],
      "metadata": {
        "id": "yvpvBONgNg3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your DataFrame 'df' here\n",
        "\n",
        "# Convert 'Document Date' to datetime if it's not already\n",
        "df['Document Date'] = pd.to_datetime(df['Document Date'])\n",
        "\n",
        "# Sort by 'Document Date' to ensure we're getting the first purchase when we group\n",
        "df.sort_values(by='Document Date', inplace=True)\n",
        "\n",
        "# Group by 'Customer Number' and get the first invoice (SOP Number) for each customer\n",
        "first_invoice_per_customer = df.groupby('Customer Number')['SOP Number'].first().reset_index()\n",
        "\n",
        "# Merge this information with df to get all rows related to the first purchases\n",
        "first_purchases = pd.merge(first_invoice_per_customer, df, on=['Customer Number', 'SOP Number'], how='left')\n",
        "\n",
        "# Now group by 'Customer Number' and count the distinct 'Item Number' for the first purchase\n",
        "distinct_products_first_purchase = first_purchases.groupby('Customer Number')['Item Number'].nunique().reset_index()\n",
        "\n",
        "# Aggregate other necessary information from the first purchase\n",
        "first_purchase_agg = first_purchases.groupby('Customer Number').agg({\n",
        "    'Document Date': 'first',\n",
        "    'Extended Price': 'sum',\n",
        "    'Location ID': 'first',\n",
        "    'SOP Number': 'first'  # Keep the SOP Number\n",
        "}).reset_index()\n",
        "\n",
        "# Merge the distinct products count into first_purchase_agg\n",
        "first_purchase_df = pd.merge(first_purchase_agg, distinct_products_first_purchase, on='Customer Number', how='left')\n",
        "\n",
        "# Check if the customer buys again (more than one unique 'SOP Number')\n",
        "buys_again = df.groupby('Customer Number')['SOP Number'].nunique() > 1\n",
        "buys_again_df = buys_again.to_frame('Buys Again').reset_index()\n",
        "buys_again_df['Buys Again'] = buys_again_df['Buys Again'].astype(int)\n",
        "first_purchase_df = pd.merge(first_purchase_df, buys_again_df, on='Customer Number', how='left')\n",
        "\n",
        "# Rename columns for clarity\n",
        "first_purchase_df.rename(columns={\n",
        "    'Item Number': 'Distinct Products in First Invoice'\n",
        "}, inplace=True)\n",
        "\n",
        "# To calculate the percentage offered, ensure 'SOP Number' is present in both dataframes\n",
        "total_qty_per_invoice = df.groupby('SOP Number')['QTY'].sum()\n",
        "offered_qty_per_invoice = df[df['Offer Status'] == 'Offer'].groupby('SOP Number')['QTY'].sum()\n",
        "percentage_offered_df = (offered_qty_per_invoice / total_qty_per_invoice).to_frame('Percentage Offered').reset_index()\n",
        "first_purchase_df = pd.merge(first_purchase_df, percentage_offered_df, on='SOP Number', how='left')\n",
        "first_purchase_df['Percentage Offered'].fillna(0, inplace=True)\n",
        "\n",
        "# Save the aggregated data\n",
        "first_purchase_df.to_csv('first_purchase_data.csv', index=False)\n",
        "print(\"Aggregated first purchase data saved to 'first_purchase_data.csv'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMtHpG-iahk3",
        "outputId": "df34d7af-1982-4f38-8920-ed2e5eeaf777"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated first purchase data saved to 'first_purchase_data.csv'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "library(dplyr)\n",
        "library(tidyr)\n",
        "library(lubridate)\n",
        "\n",
        "\n",
        "df_invoice <- df\n",
        "\n",
        "\n",
        "invoice_df <- df_invoice %>%\n",
        "  group_by(SOP_Number) %>%\n",
        "  summarise(\n",
        "    Product_Variety = n_distinct(Item_Number),\n",
        "    Category_Variety = n_distinct(Category),\n",
        "    SubCategory_Variety = n_distinct(Subcategory),\n",
        "    Total_Extended_Price = sum(Extended_Price),\n",
        "    Total_QTY = sum(QTY),\n",
        "    Customer_Number = first(Customer_Number),\n",
        "    Document_Date = first(Document_Date),\n",
        "    Location_ID = first(Location_ID),\n",
        "    SOP_Number = first(SOP_Number)\n",
        "  )\n",
        "\n",
        "# Calculate Percentage Offered and Count of Distinct Offered Items\n",
        "offered_data <- df_invoice %>%\n",
        "  filter(Offer_Status == \"Offer\") %>%\n",
        "  group_by(SOP_Number) %>%\n",
        "  summarise(\n",
        "    QTY = sum(QTY),\n",
        "    Distinct_Offered_Items = n_distinct(Item_Number)\n",
        "  )\n",
        "\n",
        "# Merging data\n",
        "invoice_df <- left_join(invoice_df, offered_data, by = \"SOP_Number\")\n",
        "invoice_df <- invoice_df %>%\n",
        "  mutate(Percentage_Offered = QTY / Total_QTY) %>%\n",
        "  select(-QTY)\n",
        "\n",
        "# Fill NaN values with appropriate defaults\n",
        "invoice_df$Percentage_Offered[is.na(invoice_df$Percentage_Offered)] <- 0\n",
        "invoice_df$Distinct_Offered_Items[is.na(invoice_df$Distinct_Offered_Items)] <- 0\n",
        "\n",
        "# Save the aggregated data to a CSV\n",
        "write.csv(invoice_df, 'invoice.csv', row.names = FALSE)\n",
        "print(\"Aggregated invoice data saved to 'invoice.csv'.\")\n"
      ],
      "metadata": {
        "id": "j47lmSrpPe2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_invoice$Document_Date <- ymd(df_invoice$Document_Date)\n",
        "\n",
        "# Ensure the DataFrame is sorted by 'Document Date'\n",
        "df_invoice <- df_invoice %>% arrange(Document_Date)\n",
        "\n",
        "calculate_rfm_up_to_date <- function(customer_number, invoice_date, df) {\n",
        "  # Filter records for the customer up to the invoice date\n",
        "  customer_data <- df %>% filter(Customer_Number == customer_number, Document_Date < invoice_date)\n",
        "\n",
        "  # Calculate Recency\n",
        "  last_purchase <- max(customer_data$Document_Date, na.rm = TRUE)\n",
        "  if (!is.na(last_purchase)) {\n",
        "    recency <- as.numeric(invoice_date - last_purchase)\n",
        "  } else {\n",
        "    # For new customers, use a large number to indicate no previous purchase\n",
        "    recency_range <- max(df$Document_Date, na.rm = TRUE) - min(df$Document_Date, na.rm = TRUE)\n",
        "    recency <- as.numeric(recency_range) + 1\n",
        "  }\n",
        "\n",
        "  # Calculate Frequency and Monetary\n",
        "  frequency <- n_distinct(customer_data$SOP_Number)\n",
        "  monetary <- sum(customer_data$Extended_Price, na.rm = TRUE)\n",
        "\n",
        "  return(c(Recency = recency, Frequency = frequency, Monetary = monetary))\n",
        "}\n",
        "\n",
        "# Create the RFM columns in invoice_df\n",
        "invoice_df$Invoice_R <- NA\n",
        "invoice_df$Invoice_F <- NA\n",
        "invoice_df$Invoice_M <- NA\n",
        "\n",
        "# Calculate RFM values for each row in invoice_df\n",
        "for (i in 1:nrow(invoice_df)) {\n",
        "  rfm_values <- calculate_rfm_up_to_date(invoice_df$Customer_Number[i], invoice_df$Document_Date[i], df_invoice)\n",
        "  invoice_df$Invoice_R[i] <- rfm_values[\"Recency\"]\n",
        "  invoice_df$Invoice_F[i] <- rfm_values[\"Frequency\"]\n",
        "  invoice_df$Invoice_M[i] <- rfm_values[\"Monetary\"]\n",
        "}\n",
        "\n",
        "# Save the results\n",
        "write.csv(invoice_df, \"invoice.csv\", row.names = FALSE)\n",
        "print(\"RFM calculations are complete and saved to invoice.csv.\")\n"
      ],
      "metadata": {
        "id": "sUj-7xGePr7m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}